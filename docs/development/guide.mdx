---
title: 'Developer Guide'
description: 'Get started with OpenMind OS (OM1)'
---

<Note>
  This guide provides a comprehensive overview of the OM1 agent runtime system, including CLI commands, project structure, development workflow, and configuration.
</Note>

## Quick Start

<Steps>
  <Step title="Install Dependencies">
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # or `.venv\Scripts\activate` on Windows
    pip install -r requirements.txt
    ```
  </Step>
  
  <Step title="Configure Environment">
    Create a `.env` file with your API keys:
    ```bash
    OPENAI_API_KEY=your_key_here
    # Add other API keys as needed
    ```
  </Step>
  
  <Step title="Run an Agent">
    ```bash
    python src/run.py start conversation --debug
    ```
  </Step>
</Steps>

## CLI Commands

The main entry point is `src/run.py` which provides the following commands:

<CodeGroup>
  ```bash Start Agent
  python src/run.py start [config_name] [--debug]
  ```
  
  ```bash Development Mode
  python src/run.py start conversation --debug
  ```
</CodeGroup>

<ResponseField name="config_name" type="string" required>
  Name of the config file (without .json extension) in the config directory
</ResponseField>

<ResponseField name="--debug" type="boolean">
  Optional flag to enable debug logging
</ResponseField>

## Project Structure

```tree
.
├── config/               # Agent configuration files
├── src/
│   ├── actions/         # Agent outputs/actions/capabilities
│   │   ├── move/       # Movement actions
│   │   ├── speak/      # Speech actions
│   │   └── face/       # Facial expressions
│   ├── fuser/          # Input fusion logic
│   ├── inputs/         # Input plugins
│   │   └── plugins/    # Input implementations
│   ├── llm/            # LLM integration
│   ├── providers/      # Shared services
│   ├── runtime/        # Core runtime system
│   ├── simulators/     # Virtual endpoints
│   └── run.py          # CLI entry point
```

## Adding New Actions

<Note>
Actions are the core capabilities of an agent. For example, for a robot, these capabilities are actions such as movement and speech.
</Note>

Each action consists of three components:

<CardGroup cols={3}>
  <Card title="Interface" icon="code">
    Defines input/output types in `interface.py`
  </Card>
  <Card title="Implementation" icon="gear">
    Business logic in `implementation/`
  </Card>
  <Card title="Connector" icon="plug">
    Hardware/API integration in `connector/`
  </Card>
</CardGroup>

Example action structure:

```tree
actions/
└── move_{unique_hardware_id}/
    ├── interface.py      # Defines MoveInput/Output
    ├── implementation/
    │   └── passthrough.py
    └── connector/
        ├── ros2.py      # ROS2 integration
        ├── zenoh.py     # Zenoh integration
        └── unitree.py   # Direct hardware control
```

## Development Tips

<Accordion title="Code Quality">
  Run linting and formatting:
  ```bash
  uv run ruff check . --fix && uv run black . && uv run isort .
  ```
</Accordion>

<Accordion title="Pre-commit Hooks">
  Install pre-commit hooks:
  ```bash
  pre-commit install
  pre-commit run --all-files  # Manual check
  ```
</Accordion>

<Accordion title="Debugging">
  - Use `--debug` flag for detailed logging
  - Test actions with `passthrough` implementation first
  - Use type hints and docstrings
</Accordion>

## Environment Variables

<ResponseField name="ETH_ADDRESS" type="string">
  Ethereum address for agent wallet (optional)
  ```bash
  ETH_ADDRESS=0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045
  ```
</ResponseField>

<ResponseField name="UNITREE_WIRED_ETHERNET" type="string">
  Network adapter for Unitree robot connection
  ```bash
  UNITREE_WIRED_ETHERNET=eno0  # or "SIM" for debugging
  ```
</ResponseField>

## LLM Configuration

OpenMind provides proxy endpoints for various LLM services:

<CodeGroup>
```json OpenAI
{
  "type": "OpenAILLM",
  "config": {
    "base_url": "https://api.openmind.org/api/core/openai",
    "api_key": "your_key_here"
  }
}
```

```json DeepSeek
{
  "type": "DeepSeekLLM",
  "config": {
    "base_url": "https://api.openmind.org/api/core/deepseek",
    "api_key": "your_key_here"
  }
}
```

```json Gemini
{
  "type": "GeminiLLM",
  "config": {
    "base_url": "https://api.openmind.org/api/core/gemini",
    "api_key": "your_key_here"
  }
}
```
</CodeGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Add Custom Actions" icon="plus" href="/docs/development/actions">
    Learn how to create new agent capabilities
  </Card>
  <Card title="Configure Inputs" icon="gear" href="/docs/development/inputs">
    Set up input sources for your agent
  </Card>
  <Card title="Deploy" icon="rocket" href="/docs/deployment">
    Deploy your agent to production
  </Card>
  <Card title="Examples" icon="code" href="/docs/examples">
    Explore example configurations
  </Card>
</CardGroup>
