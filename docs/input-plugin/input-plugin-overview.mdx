---
title: Input Plugin Overview
description: "Input plugin overview"
---

## Input Plugin Overview

The Input Plugins in OM1 provide the sensory capabilities that allow AI agents to perceive and interact with their environment. These plugins capture, process, and format various types of input data from different sources, making them available to the agent's runtime core for decision-making.

[All the input plugins codes](https://github.com/OpenmindAGI/OM1/tree/main/src/inputs)

## Input Plugin Architecture

### Classes Diagram

In order to simplify the diagram, we only show the most important classes and their relationships.

```mermaid
classDiagram
    class SensorConfig {
        +__init__(**kwargs)
    }

    class Sensor~R~ {
        <<abstract>>
        +__init__(config: SensorConfig)
        +async _raw_to_text(raw_input: R) str
        +async raw_to_text(raw_input: R)
        +formatted_latest_buffer() str|None
        +async listen() AsyncIterator[R]
    }

    class VLMBase {
        +async _raw_to_text(raw_input: bytes) str
        +formatted_latest_buffer() str
    }

    class SerialReader {
        +async _listen_loop() AsyncIterator[bytes]
    }

    class GPSMagSerialReader {
        +async _raw_to_text(raw_input: bytes) str
    }

    class VLMCOCOLocal {
        +async _raw_to_text(raw_input: bytes) str
    }

    class VLMOpenAI {
        +async _raw_to_text(raw_input: bytes) str
    }

    class VLMVila {
        +async _raw_to_text(raw_input: bytes) str
    }

    class UnitreeGo2Camera {
        +async _listen_loop() AsyncIterator[bytes]
    }

    class UnitreeGo2LowState {
        +async _listen_loop() AsyncIterator[bytes]
    }

    SensorConfig --> Sensor
    Sensor <|-- VLMBase
    Sensor <|-- SerialReader
    SerialReader <|-- GPSMagSerialReader
    VLMBase <|-- VLMCOCOLocal
    VLMBase <|-- VLMOpenAI
    VLMBase <|-- VLMVila
    Sensor <|-- UnitreeGo2Camera
    Sensor <|-- UnitreeGo2LowState
```

- [class `Sensor`](https://github.com/OpenmindAGI/OM1/blob/8c73b76b54d1c379998be5f75a6b04e43e6a4701/src/inputs/base/__init__.py#L23)
- [class `FuserInput`](https://github.com/OpenmindAGI/OM1/blob/8c73b76b54d1c379998be5f75a6b04e43e6a4701/src/inputs/base/loop.py#L8)

### Data Flow Diagram

```mermaid
flowchart TD
    subgraph Input Sources
        A1[Camera Input]
        A2[Serial Port Input]
        A3[Robot State Input]
        A4[VLM Cloud Input]
    end

    subgraph Sensor Processing
        B1[VLM_COCO_Local]
        B2[GPSMagSerialReader]
        B3[UnitreeGo2LowState]
        B4[VLM Cloud Services]
    end

    subgraph Data Transformation
        C1[Raw to Text Conversion]
        C2[Message Formatting]
        C3[Buffer Management]
    end

    subgraph Orchestration
        D1[InputOrchestrator]
        D2[Async Task Management]
    end

    subgraph Output
        E1[Formatted Messages]
        E2[Text Stream]
    end

    %% Input Sources to Sensors
    A1 --> B1
    A2 --> B2
    A3 --> B3
    A4 --> B4

    %% Sensor Processing
    B1 --> C1
    B2 --> C1
    B3 --> C1
    B4 --> C1

    %% Data Transformation
    C1 --> C2
    C2 --> C3

    %% Orchestration
    C3 --> D1
    D1 --> D2

    %% Output
    D2 --> E1
    D2 --> E2

    %% Detailed Data Flow for VLM_COCO_Local
    subgraph VLM_COCO_Local Flow
        F1[Image Capture]
        F2[Object Detection]
        F3[Position Analysis]
        F4[Message Generation]
    end

    F1 --> F2
    F2 --> F3
    F3 --> F4
    F4 --> C1
```
## Key relationships and notes:

### Inheritance Hierarchy

- `Sensor<T>` is the base abstract class that defines the core interface
- `FuserInput<T>` extends `Sensor<T>` and implements the polling mechanism
- `VLM_COCO_Local` extends `FuserInput<T>` and implements the specific VLM functionality

### Key Components

- Uses PyTorch's `FasterRCNN_MobileNet_V3_Large_320_FPN` model
- Processes images from webcam or other sources
- Detects objects using COCO dataset classes
- Provides spatial awareness (left/right/front)

### Key Functionality

- Real-time object detection
- Spatial object localization
- Message buffering and formatting
- Webcam integration

## Other Input Plugins

- [Google ASR](https://github.com/OpenmindAGI/OM1/blob/main/src/inputs/plugins/google_asr.py)
- [Riva ASR](https://github.com/OpenmindAGI/OM1/blob/main/src/inputs/plugins/riva_asr.py)
- [RPLidar](https://github.com/OpenmindAGI/OM1/blob/main/src/inputs/plugins/rplidar.py)
- [VLM_COCO_Local](https://github.com/OpenmindAGI/OM1/blob/main/src/inputs/plugins/vlm_coco_local.py)
- [VLM_Villa](https://github.com/OpenmindAGI/OM1/blob/main/src/inputs/plugins/vlm_vila.py)
- [Arduino GPS](https://github.com/OpenmindAGI/OM1/blob/main/src/inputs/plugins/gps_mag_serial_reader.py)