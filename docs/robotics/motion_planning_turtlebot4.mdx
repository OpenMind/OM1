---
title: TurtleBot4 Autonomous Movement Logic
description: "TurtleBot4 Autonomous Movement Logic"
---

- [Overview](#overview)
  * [TB4 RPLIDAR Laserscan Data](#tb4-rplidar-laserscan-data)
  * [Core LLM Directed Motion](#core-llm-directed-motion)
  * [TB4 Collision Switches](#tb4-collision-switches)
- [Data Priorities](#data-priorities)
  * [Normal case](#normal-case)
  * [Object nearby - possibble moves are constrained](#object-nearby---possibble-moves-are-constrained)
  * [Collision - switches triggered](#collision---switches-triggered)

## Overview

Using OM1, the TurtleBot4 is able to autonomously explore spaces such as your home. There are several parts to this capability. To get started, launch OM1:

```bash Run OM1 turtlebot4 agent
uv run src/run.py turtlebot4_lidar
```

### TB4 RPLIDAR Laserscan Data

OM1 uses the TB4's RPLIDAR to tell the core LLMs about nearby objects. This information flows to the core LLMs from `/input/plugins/rplidar.py`. The LIDAR data are also used in the action driver to check for viable paths before motions are executed. 

Please see the [RPLidar setup documentation](motion_planning_lidarA1M8) for more information.

### Core LLM Directed Motion

Depending on the environment of the TB4, the core LLMs can generate contextually appropriate motion commands. 

```py
# /actions/move_turtle/interface.py
  TURN_LEFT = "turn left"
  TURN_RIGHT = "turn right"
  MOVE_FORWARDS = "move forwards"
  STAND_STILL = "stand still"
```
These commands are defined in `actions/move_turtle/interface.py` and are converted to TB4 zenoh/cycloneDDS `cmd_vel` motions in `/actions/move_turtle/connector/zenoh.py`:

```py
# /actions/move_turtle/connector/zenoh.py
if output_interface.action == "turn left":
  # turn 90 Deg to the left (CCW)
  target_yaw = self.yaw_now - 90.0
  if target_yaw <= -180: target_yaw += 360.0
  self.pending_movements.put([0.0, target_yaw, "turn"])

...

t = geometry_msgs.Twist(
  linear=geometry_msgs.Vector3(x=float(vx), y=0.0, z=0.0),
  angular=geometry_msgs.Vector3(x=0.0, y=0.0, z=float(vyaw)),
)
self.session.put(self.cmd_vel, t.serialize())
```

### TB4 Collision Switches

* TB4 Basic Low Level (Firmware) Collision Avoidance

This logic consists of backing off about 10 cm after a frontal collision. That is handled within the `Create3` and cannot be changed by a user.

* TB4 Enhanced Collision Avoidance

OM1 uses the TB4's collision switches to invoke an enhanced emergency object avoidance behavior, which consists of turning 100 deg left or right, depending on which switch was triggered. This "turning to face away" from the object is handled inside the `action` driver to ensure prompt responses to physical collisions:

```py
# /actions/move_turtle/connector/zenoh.py

def listenerHazard(data):
    global gHazard
    gHazard = sensor_msgs.HazardDetectionVector.deserialize(data.payload.to_bytes())

...

if gHazard is not None and gHazard.detections and len(gHazard.detections) > 0:
  for haz in gHazard.detections:
      if haz.type == 1:
          if "right" in haz.header.frame_id:
              self.hazard = "TURN_LEFT"

...

if self.hazard is not None:
  if self.hazard == "TURN_RIGHT":
      target_yaw = self.yaw_now + 100.0
      if target_yaw >= 180.0: target_yaw -= 360.0
      self.emergency = target_yaw
```

## Data Priorities

### Normal case

* The LIDAR does not sense anything in proximity (within 1 m or closer).
* The collision switches are open

In this case, the TB4 moves about the room controlled by the core LLMs. 

### Object nearby - possibble moves are constrained

* The LIDAR senses something in proximity and uses that to tell the core LLMs about which paths are possible.
* The collision switches are open

In this case, the core LLMs **should** command the TB4 to turn away from the object. 

### Collision - switches triggered

* The collision switches are triggered

In this case, the firmware logic will command a 10 cm retreat, and then, the `action` level collision avoidance code will command a hard-coded 100 deg avoidance rotation. Once this rotation is complete, the system reverts to responding to commands from the core LLMs. 
