---
title: Riva Speech Recognition
description: "Real-time Speech Recognition API Reference"
---

# Riva Speech Recognition API

OpenMind's self-hosted Riva ASR (Automatic Speech Recognition) service provides real-time speech-to-text capabilities. The API utilizes WebSocket connections for minimal latency and efficient streaming.

## Base URL
```
wss://api-asr.openmind.org
```

## Authentication
Authentication is performed via API key as a query parameter:
```
?api_key=<YOUR_API_KEY>
```

## Installation

The `OM1` package provides a convenient client for interacting with the ASR API. Install using either of these methods:

Using `uv` (recommended):
```bash
uv pip3 install git+https://github.com/OpenmindAGI/OM1.git
```

Using pip:
```bash
pip3 install git+https://github.com/OpenmindAGI/OM1.git
```

## Quick Start

Here's a minimal example demonstrating real-time speech recognition:

```python
import time
from om1_utils import ws
from om1_speech import AudioInputStream

# Initialize WebSocket client with authentication
ws_client = ws.Client(url="wss://api-asr.openmind.org?api_key=<YOUR_API_KEY>")
audio_stream_input = AudioInputStream(audio_data_callback=ws_client.send_message)

# Start streaming
ws_client.start()
audio_stream_input.start()

# Handle transcription results
ws_client.register_message_callback(lambda msg: print(msg))

# Keep the connection alive
while True:
    time.sleep(1)
```

## Response Format

The API returns transcription results in JSON format:

```json
{
  "asr_reply": "hello world"
}
```