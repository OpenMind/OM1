---
title: LLM Integration
description: "LLM Integration"
---

## LLM Integration

The LLM Integration in OM1 provides the ability to integrate with LLM models. This integration allows AI agents to use LLM models to make decisions and take actions.

## LLM Integration components

[github codes](https://github.com/openmind/OM1/tree/main/src/llm)

### Class Diagram

In order to simplify the diagram, we only show the most important classes and their relationships.

```mermaid
classDiagram
    class LLMConfig {
        +__getitem__(item: str) Any
        +__setitem__(key: str, value: Any)
    }

    class LLM~R~ {
        <<abstract>>
        +async ask(prompt: str, messages: List[Dict[str, str]]) R
    }

    class Command {
    }

    class CortexOutputModel {
    }

    class OpenAILLM {
        +async ask(prompt: str, messages: List[Dict[str, str]]) R
    }

    class MultiLLM {
        +async ask(prompt: str, messages: List[Dict[str, str]]) R
    }

    class RAGMultiLLM {
        +async ask(prompt: str, messages: List[Dict[str, str]]) R
    }

    LLMConfig --> LLM
    LLM --> Command
    Command --> CortexOutputModel
    LLM <|-- OpenAILLM
    LLM <|-- MultiLLM
    LLM <|-- RAGMultiLLM
```

### Data Flow

```mermaid
sequenceDiagram
    participant Client
    participant LLM
    participant LLMConfig
    participant OutputModel
    participant IOProvider

    Note over Client: Initialize LLM
    Client->>LLMConfig: Create configuration
    Client->>LLM: Initialize with config
    
    loop LLM Interaction
        Client->>LLM: ask(prompt, messages)
        LLM->>LLMConfig: Get configuration
        LLM->>OutputModel: Validate response
        LLM->>IOProvider: Log interaction
        LLM-->>Client: Return typed response
    end
```

### Example configuration

```
  "cortex_llm": {
    "type": "OpenAILLM",
    "config": {
      "base_url": "", // Optional: URL of the LLM endpoint
      "agent_name": "Iris", // Optional: Name of the agent
      "history_length": 10
    }
  },
```